{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae8efbd4-9858-408b-8988-dfacb769714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pccv\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in c:\\users\\pccv\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: bert-score in c:\\users\\pccv\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas in c:\\users\\pccv\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pccv\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch bert-score pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "835a4872-45d3-483e-b2f5-2fb93b92206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from bert_score import score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "760b7e11-c8ba-4eb9-b6e0-807e3c342871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1: Load GPT-2 Model and Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66bd0cf4-a50b-4d96-98d8-432d96b47084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pad_token_id explicitly to eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d76e0d3-6324-42aa-9847-5e79d21d1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text with GPT-2\n",
    "def generate_quote(prompt, max_length=50, num_outputs=3):\n",
    "    outputs = []\n",
    "    for _ in range(num_outputs):\n",
    "        # Tokenize input with attention_mask\n",
    "        inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        # Generate text with explicit attention_mask and pad_token_id\n",
    "        outputs_gen = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,  # Use the function parameter\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(outputs_gen[0], skip_special_tokens=True)\n",
    "        # Remove the prompt from the output\n",
    "        generated_text = generated_text[len(prompt):].strip()\n",
    "        outputs.append(generated_text)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0795cc16-fb98-4ee2-aa38-f72385cc88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Design 5 Distinct Prompts\n",
    "prompts = {\n",
    "    \"Direct\": \"Write a motivational quote about overcoming fear.\",\n",
    "    \"Scenario-based\": \"Imagine youâ€™re helping a friend who failed a test. Write something encouraging.\",\n",
    "    \"Persona-based\": \"As a wise monk, write a quote about inner strength.\",\n",
    "    \"Keyword-based\": \"Using the words 'growth', 'struggle', and 'hope', write something inspiring.\",\n",
    "    \"Conversational\": \"User: I feel like giving up. GPT-2: Here's a quote for you:\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66109496-15d2-4803-b4e1-b2e33199f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3 outputs for each prompt\n",
    "results = {}\n",
    "for prompt_type, prompt_text in prompts.items():\n",
    "    generated_outputs = generate_quote(prompt_text, max_length=50, num_outputs=3)\n",
    "    results[prompt_type] = generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7db50aad-7455-40e2-8de8-294285dae9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Human-Written Reference\n",
    "human_reference = (\n",
    "    \"The greatest glory in living lies not in never falling, but in rising every time we fall.\"\n",
    ")\n",
    "reference_source = \"https://www.brainyquote.com/quotes/nelson_mandela_378967\"\n",
    "\n",
    "# Part 4: Evaluate Outputs Using BERTScore\n",
    "def compute_bertscore(generated_texts, reference_text):\n",
    "    P, R, F1 = score(generated_texts, [reference_text] * len(generated_texts), lang='en', verbose=True)\n",
    "    return F1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79ecca7c-484b-4990-8e21-cd61d78dba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d636b27b1b44128e974b9611151b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452ac50decb643d792754946f00bc70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.24 seconds, 4.63 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Collect all generated texts and compute BERTScores\n",
    "all_generated_texts = []\n",
    "prompt_types = []\n",
    "output_numbers = []\n",
    "\n",
    "for prompt_type, outputs in results.items():\n",
    "    for i, output in enumerate(outputs, 1):\n",
    "        all_generated_texts.append(output)\n",
    "        prompt_types.append(prompt_type)\n",
    "        output_numbers.append(i)\n",
    "\n",
    "bert_scores = compute_bertscore(all_generated_texts, human_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fa49509-992d-466b-92bb-969d70aa068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Results Table\n",
    "results_table = pd.DataFrame({\n",
    "    'Prompt Type': prompt_types,\n",
    "    'Output #': output_numbers,\n",
    "    'Generated Text': all_generated_texts,\n",
    "    'BERTScore F1': bert_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6a9a3fd-22e4-4ce2-b0ca-5c3005820a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prompts ===\n",
      "Direct: Write a motivational quote about overcoming fear.\n",
      "Scenario-based: Imagine youâ€™re helping a friend who failed a test. Write something encouraging.\n",
      "Persona-based: As a wise monk, write a quote about inner strength.\n",
      "Keyword-based: Using the words 'growth', 'struggle', and 'hope', write something inspiring.\n",
      "Conversational: User: I feel like giving up. GPT-2: Here's a quote for you:\n",
      "\n",
      "=== Generated Outputs ===\n",
      "\n",
      "Direct:\n",
      "Output 1: 3. Take a mental step toward self-help\n",
      "\"I want you to be a human being. Do you think you can do that, if you have to spend time with your friends and family\n",
      "Output 2: Take a step away from the big scary words and make the point that the fear is real. It is easy to forget about the scary things that you have to deal with in order to feel good at something.\n",
      "Output 3: You can use this tool to ask your partner questions about the things you'd like to discuss in your life. Ask them about specific topics that you have been thinking about or trying out the next time. Try to\n",
      "\n",
      "Scenario-based:\n",
      "Output 1: It is difficult to believe that those who test positive are so lucky. There is no such thing as a normal kid who scores below 60 or 80%.\n",
      "Output 2: How to Do It\n",
      ". Go in, write. You can't let a failure get in the way of getting a smile. The most important thing to\n",
      "Output 3: Helping someone make a decision to quit a job. Make sure you feel well. Try to make your body the best you can, not the weakest you may ever\n",
      "\n",
      "Persona-based:\n",
      "Output 1: A word that goes without saying. How the heart is broken by your lack of inner self-control. (A:1)\n",
      ", I feel like my heart broke in two\n",
      "Output 2: You can write about the inner power, or you can just do it with something like this.\n",
      "\n",
      "You can feel the desire for things you really want, and you will feel this intense\n",
      "Output 3: That's where you put your wisdom, your heart, and your soul.\n",
      "\n",
      "It's always better to have my body in the right place than my soul to be in a body that\n",
      "\n",
      "Keyword-based:\n",
      "Output 1: The good news is that we are all getting ready for this world. If we want to change, we have to look in different directions. This\n",
      "Output 2: If it sounds like something you'd like to give, call your representative and get in touch about it. And if not, contact them directly.\n",
      "Output 3: You will discover that this is the best way of connecting and expressing the feelings and thoughts you already share.\n",
      "\n",
      "Your mind, your mind.\n",
      "\n",
      "Conversational:\n",
      "Output 1: \"Let's be careful, we'll be doing what we do bestâ€”and what will go in.\"\n",
      "\n",
      "Kris: Hey, I'm\n",
      "Output 2: (from http://www.twitch.tv/r/Bungie) \"I thought we were a little far ahead of everybody (it had\n",
      "Output 3: \"If you think that you can win an X match in one round, your best bet is to keep it short and narrow as it happens. You\n",
      "\n",
      "=== Human-Written Reference ===\n",
      "Quote: The greatest glory in living lies not in never falling, but in rising every time we fall.\n",
      "Source: https://www.brainyquote.com/quotes/nelson_mandela_378967\n",
      "\n",
      "=== BERTScore Results Table ===\n",
      "       Prompt Type  Output #  BERTScore F1\n",
      "0           Direct         1      0.838013\n",
      "1           Direct         2      0.845510\n",
      "2           Direct         3      0.837258\n",
      "3   Scenario-based         1      0.837919\n",
      "4   Scenario-based         2      0.839941\n",
      "5   Scenario-based         3      0.835150\n",
      "6    Persona-based         1      0.839515\n",
      "7    Persona-based         2      0.845088\n",
      "8    Persona-based         3      0.845149\n",
      "9    Keyword-based         1      0.853933\n",
      "10   Keyword-based         2      0.838962\n",
      "11   Keyword-based         3      0.848493\n",
      "12  Conversational         1      0.816065\n",
      "13  Conversational         2      0.809674\n",
      "14  Conversational         3      0.843441\n",
      "\n",
      "Results saved to 'motivational_quotes_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\n=== Prompts ===\")\n",
    "for prompt_type, prompt_text in prompts.items():\n",
    "    print(f\"{prompt_type}: {prompt_text}\")\n",
    "\n",
    "print(\"\\n=== Generated Outputs ===\")\n",
    "for prompt_type, outputs in results.items():\n",
    "    print(f\"\\n{prompt_type}:\")\n",
    "    for i, output in enumerate(outputs, 1):\n",
    "        print(f\"Output {i}: {output}\")\n",
    "\n",
    "print(\"\\n=== Human-Written Reference ===\")\n",
    "print(f\"Quote: {human_reference}\")\n",
    "print(f\"Source: {reference_source}\")\n",
    "\n",
    "print(\"\\n=== BERTScore Results Table ===\")\n",
    "print(results_table[['Prompt Type', 'Output #', 'BERTScore F1']])\n",
    "\n",
    "# Save results to a CSV file (optional)\n",
    "results_table.to_csv('motivational_quotes_results.csv', index=False)\n",
    "print(\"\\nResults saved to 'motivational_quotes_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b167b8-cbb6-4636-a22a-e49fdaae64d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
